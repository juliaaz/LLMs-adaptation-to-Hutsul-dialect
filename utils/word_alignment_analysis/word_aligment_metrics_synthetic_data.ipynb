{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7abe15a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/Julia/Library/Python/3.8/lib/python/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/Julia/Library/Python/3.8/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /Users/Julia/Library/Python/3.8/lib/python/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Julia/Library/Python/3.8/lib/python/site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.8.1 has a non-standard dependency specifier torch>=1.9.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "332981aa-3b4e-4ba5-8fa4-16742c0d477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def convert_json_to_alignment(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    aligned_sentences = []\n",
    "    for item in data:\n",
    "        hut_text = item['hut']\n",
    "        ukr_text = item['ukr']\n",
    "        aligned_sentences.append(f\"{hut_text} ||| {ukr_text}\")\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for sentence in aligned_sentences:\n",
    "            file.write(sentence + '\\n')\n",
    "\n",
    "def convert_csv_to_alignment(input_file, output_file):\n",
    "    aligned_sentences = []\n",
    "    with open(input_file, 'r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            hut_text = row['Sentence']\n",
    "            ukr_text = row['Synthetic_Sentence']\n",
    "            aligned_sentences.append(f\"{hut_text} ||| {ukr_text}\")\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for sentence in aligned_sentences:\n",
    "            file.write(sentence + '\\n')\n",
    "\n",
    "convert_csv_to_alignment(\"hutsul_synthetic_base.csv\", \"corpus_synthetic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3839117-cc9c-45d2-9411-36faf0545cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words aligned in the same position: 43143\n",
      "Words aligned in different positions: 818\n"
     ]
    }
   ],
   "source": [
    "same_position_count = 0\n",
    "different_position_count = 0\n",
    "\n",
    "with open('symmetric.align', 'r') as file:\n",
    "    for line in file:\n",
    "        alignments = line.strip().split()\n",
    "        \n",
    "        for alignment in alignments:\n",
    "            source, target = map(int, alignment.split('-'))\n",
    "            if source == target or source == target+1 or source == target-1:\n",
    "                same_position_count += 1\n",
    "            else:\n",
    "                different_position_count += 1\n",
    "\n",
    "print(f\"Words aligned in the same position: {same_position_count}\")\n",
    "print(f\"Words aligned in different positions: {different_position_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca903f00-4c94-451b-bc45-77023f0b11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_pairs = []\n",
    "\n",
    "with open('corpus_synthetic.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())\n",
    "        source, target = line.strip().split(' ||| ')  # Splitting by ' ||| '\n",
    "        \n",
    "        source_words = source.split()\n",
    "        target_words = target.split()\n",
    "        \n",
    "        source_lengths = [len(word) for word in source_words]\n",
    "        target_lengths = [len(word) for word in target_words]\n",
    "        \n",
    "        sentence_pairs.append((source_lengths, target_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92fe54c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6490"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef690c28-fbd3-4683-8800-b1ddd640ae5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 2, 4, 6], [4, 2, 4, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcb26880-04ef-40e5-adda-543da88dac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments = []\n",
    "\n",
    "with open('symmetric.align', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        alignment_pairs = line.strip().split()\n",
    "        sentence_alignments = [tuple(map(int, pair.split('-'))) for pair in alignment_pairs]\n",
    "        \n",
    "        alignments.append(sentence_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "141be11a-0804-4706-a7d4-0d859aeb9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-src (Proportion of unaligned source characters): 0.001\n",
      "U-tgt (Proportion of unaligned target characters): 0.002\n",
      "X (Proportion of crossing alignment pairs): 0.013\n"
     ]
    }
   ],
   "source": [
    "total_src_chars = 0\n",
    "total_tgt_chars = 0\n",
    "unaligned_src_chars = 0\n",
    "unaligned_tgt_chars = 0\n",
    "crossing_pairs = 0\n",
    "total_aligned_pairs = 0\n",
    "\n",
    "for pair_idx, (src_lengths, tgt_lengths) in enumerate(sentence_pairs):\n",
    "    aligned_src_indices = set()\n",
    "    aligned_tgt_indices = set()\n",
    "    total_src_chars += sum(src_lengths)\n",
    "    total_tgt_chars += sum(tgt_lengths)\n",
    "    for (src_idx, tgt_idx) in alignments[pair_idx]:\n",
    "        if src_idx >= len(src_lengths) or tgt_idx >= len(tgt_lengths):\n",
    "            continue\n",
    "        aligned_src_indices.update(range(sum(src_lengths[:src_idx]), sum(src_lengths[:src_idx + 1])))\n",
    "        aligned_tgt_indices.update(range(sum(tgt_lengths[:tgt_idx]), sum(tgt_lengths[:tgt_idx + 1])))\n",
    "\n",
    "        for (other_src_idx, other_tgt_idx) in alignments[pair_idx]:\n",
    "            if (src_idx < other_src_idx and tgt_idx > other_tgt_idx) or (src_idx > other_src_idx and tgt_idx < other_tgt_idx):\n",
    "                crossing_pairs += 1\n",
    "\n",
    "    unaligned_src_chars += len([char for idx, char in enumerate(range(sum(src_lengths))) if idx not in aligned_src_indices])\n",
    "    unaligned_tgt_chars += len([char for idx, char in enumerate(range(sum(tgt_lengths))) if idx not in aligned_tgt_indices])\n",
    "    total_aligned_pairs += len(alignments[pair_idx])\n",
    "\n",
    "u_src = unaligned_src_chars / total_src_chars\n",
    "u_tgt = unaligned_tgt_chars / total_tgt_chars\n",
    "x = crossing_pairs / total_aligned_pairs if total_aligned_pairs > 0 else 0\n",
    "\n",
    "print(f\"U-src (Proportion of unaligned source characters): {u_src:.3f}\")\n",
    "print(f\"U-tgt (Proportion of unaligned target characters): {u_tgt:.3f}\")\n",
    "print(f\"X (Proportion of crossing alignment pairs): {x:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
